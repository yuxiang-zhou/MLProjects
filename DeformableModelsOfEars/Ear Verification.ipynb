{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ear Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "from menpo import io as mio\n",
    "from menpo.visualize import print_dynamic\n",
    "from sklearn.utils.fixes import bincount\n",
    "import itertools\n",
    "import warnings\n",
    "from sklearn.utils import check_X_y, check_array\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from dAAMs.lda import lda, predict, chunk, n_fold_generate\n",
    "from menpo.feature import igo, hog, no_op, double_igo as digo, dsift, fast_dsift, hellinger_vector_128_dsift, gradient\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc\n",
    "from menpo.model import PCAModel, PCAVectorModel\n",
    "from dAAMs.fisher import FisherVector\n",
    "import functools\n",
    "\n",
    "data_cache = {}\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mod_igos(pixels, double_angles=False):\n",
    "\n",
    "    if len(pixels.shape) != 3:\n",
    "        raise ValueError('IGOs only work on 2D images. Expects image data to be 3D, channels + shape.')\n",
    "                \n",
    "    n_img_chnls = pixels.shape[0]\n",
    "\n",
    "    feat_chnls = 2\n",
    "    if double_angles:\n",
    "        feat_chnls = 4\n",
    "\n",
    "    grad = gradient(pixels)\n",
    "    grad_orient = np.angle(grad[:n_img_chnls] + 1j * grad[n_img_chnls:])\n",
    "\n",
    "    if double_angles:\n",
    "        grad_orient = np.hstack([grad_orient, 2*grad_orient])\n",
    "\n",
    "    return grad_orient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### classification functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dAAMs.lda import lda, predict, chunk, n_fold_generate, decision_function\n",
    "class LDAWrap:\n",
    "    def __init__(self):\n",
    "        self.intercept_ = None\n",
    "        self.coef_ = None\n",
    "        self.classes_ = None\n",
    "    def fit(self,train_X, train_y):\n",
    "        self.intercept_, self.coef_, self.classes_ = lda(train_X, train_y)\n",
    "    def predict(self, test_X):\n",
    "        return predict(test_X, self.intercept_, self.coef_, self.classes_)\n",
    "    def decision_function(self, test_X):\n",
    "        return decision_function(test_X,self.intercept_, self.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class JBC:\n",
    "    def __init__(self):\n",
    "        self._A = None\n",
    "        self._G = None\n",
    "    def fit(self,train_X, train_y):\n",
    "        X_I = []\n",
    "        X_E = []\n",
    "        for (v1,v2),label in zip(train_X, train_y):\n",
    "            if label > 0:\n",
    "                X_I.append(np.concatenate([v1,v2]).reshape(-1,1))\n",
    "            else:\n",
    "                X_E.append(np.concatenate([v1,v2]).reshape(-1,1))\n",
    "                \n",
    "        print('computing cov Matrixes with size: {} * {}'.format(len(X_I), len(X_I[0])))\n",
    "        \n",
    "        covI = np.cov(np.hstack(X_I))\n",
    "        covE = np.cov(np.hstack(X_E))\n",
    "        size = covI.shape[0] / 2\n",
    "        inverseI = np.linalg.inv(covI)\n",
    "        inverseE = np.linalg.inv(covE)\n",
    "        \n",
    "        \n",
    "        _F = inverseI[0:size,0:size]\n",
    "        _G = inverseI[0:size,size:]\n",
    "        _temp = np.zeros(inverseE.shape)\n",
    "        _temp[0:size,0:size] = _F\n",
    "        _temp[size:,size:] = _F\n",
    "        _A = (inverseE - _temp)[0:size,0:size]\n",
    "        \n",
    "        self._A = _A\n",
    "        self._G = _G\n",
    "        \n",
    "    def predict(self, test_X):\n",
    "        return self.decision_function(test_X) > 0\n",
    "    \n",
    "    def decision_function(self, test_X):\n",
    "        def df(self, v1, v2):\n",
    "            return v1.T.dot(self._A).dot(v1) + v2.T.dot(self._A).dot(v2) - 2 * v1.T.dot(self._G).dot(v2)\n",
    "        \n",
    "        return np.array([df(self,v1,v2) for v1,v2 in test_X])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_cosine(trains,tests):\n",
    "    ret_train = []\n",
    "    ret_test = []\n",
    "    \n",
    "    for v1,v2 in trains:\n",
    "        phi1 = mod_igos(v1)\n",
    "        phi2 = mod_igos(v2)\n",
    "        dphi = phi1-phi2\n",
    "        ret_train.append(np.mean(np.cos(dphi)))\n",
    "        \n",
    "    for v1,v2 in tests:\n",
    "        phi1 = mod_igos(v1)\n",
    "        phi2 = mod_igos(v2)\n",
    "        dphi = phi1-phi2\n",
    "        ret_test.append(np.mean(np.cos(dphi)))\n",
    "        \n",
    "    return ret_train, ret_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_concat(trains,tests):\n",
    "    ret_train = []\n",
    "    ret_test = []\n",
    "    \n",
    "    for v1,v2 in trains:\n",
    "        ret_train.append(np.concatenate([v1,v2]))\n",
    "        \n",
    "    for v1,v2 in tests:\n",
    "        ret_test.append(np.concatenate([v1,v2]))\n",
    "        \n",
    "    return ret_train, ret_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_diff(trains,tests):\n",
    "    ret_train = []\n",
    "    ret_test = []\n",
    "    \n",
    "    for v1,v2 in trains:\n",
    "        ret_train.append(v1-v2)\n",
    "        \n",
    "    for v1,v2 in tests:\n",
    "        ret_test.append(v1-v2)\n",
    "        \n",
    "    return ret_train, ret_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_l2norm(trains,tests):\n",
    "    ret_train = []\n",
    "    ret_test = []\n",
    "    \n",
    "    for v1,v2 in trains:\n",
    "        ret_train.append(np.linalg.norm(v1-v2))\n",
    "        \n",
    "    for v1,v2 in tests:\n",
    "        ret_test.append(np.linalg.norm(v1-v2))\n",
    "        \n",
    "    return ret_train, ret_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "def pair_preprocess_pca(trains,tests, ratio=0.9):\n",
    "    ret_train = []\n",
    "    ret_test = []\n",
    "    \n",
    "    tr1,tr2 = list(zip(*trains))\n",
    "    t1,t2 = list(zip(*tests))\n",
    "      \n",
    "    pca = PCAVectorModel(tr1 + tr2)\n",
    "    \n",
    "    if ratio < 1:\n",
    "        n_active_component = np.argwhere(pca.eigenvalues_cumulative_ratio() > ratio)[0][0]\n",
    "    else:\n",
    "        n_active_component = ratio\n",
    "    \n",
    "    pca.n_active_components = n_active_component\n",
    "    \n",
    "    \n",
    "    ret_train,ret_test = list(zip([pca.project(vec) for vec in tr1],[pca.project(vec) for vec in tr2])),list(zip([pca.project(vec) for vec in t1],[pca.project(vec) for vec in t2]))\n",
    "    \n",
    "    return ret_train, ret_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_fv(trains,tests, K=128):\n",
    "    ret_train = []\n",
    "    ret_test = []\n",
    "    \n",
    "    tr1,tr2 = list(zip(*trains))\n",
    "    t1,t2 = list(zip(*tests))\n",
    "    \n",
    "    fv = FisherVector(tr1+tr2, K=K)\n",
    "    \n",
    "    ret_train,ret_test = list(zip([fv.generate(vec, normalise=True) for vec in tr1],[fv.generate(vec, normalise=True) for vec in tr2])),list(zip([fv.generate(vec, normalise=True) for vec in t1],[fv.generate(vec, normalise=True) for vec in t2]))\n",
    "    \n",
    "    return ret_train, ret_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_fv_all(trains,tests, K=128):\n",
    "    ret_train = []\n",
    "    ret_test = []\n",
    "    \n",
    "    tr1,tr2 = list(zip(*trains))\n",
    "    t1,t2 = list(zip(*tests))\n",
    "    \n",
    "    fv = FisherVector(tr1+tr2, K=K)\n",
    "    \n",
    "    ret_train,ret_test = [fv.generate([v1,v2], normalise=True) for v1,v2 in trains],[fv.generate([v1,v2], normalise=True) for v1,v2 in tests]\n",
    "    \n",
    "    return ret_train, ret_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_fv_l2norm(trains,tests, K=128):\n",
    "    ret_train = []\n",
    "    ret_test = []\n",
    "    \n",
    "    tr1,tr2 = list(zip(*trains))\n",
    "    t1,t2 = list(zip(*tests))\n",
    "    \n",
    "    fv = FisherVector(tr1+tr2, K=K)\n",
    "    \n",
    "    ret_train,ret_test = [np.linalg.norm(fv.generate([v1,v2], normalise=True)) for v1,v2 in trains],[np.linalg.norm(fv.generate([v1,v2], normalise=True)) for v1,v2 in tests]\n",
    "    \n",
    "    return ret_train, ret_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_pca_fv(trains,tests, ratio=0.9, K=128):\n",
    "    ret_train, ret_test = pair_preprocess_pca(trains,tests, ratio)\n",
    "    return pair_preprocess_fv(ret_train, ret_test, K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_pca_fv_all(trains,tests, ratio=0.9, K=128):\n",
    "    ret_train, ret_test = pair_preprocess_pca(trains,tests, ratio)\n",
    "    return pair_preprocess_fv_all(ret_train, ret_test, K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_pca_fv_all_l2norm(trains,tests, ratio=0.9, K=128):\n",
    "    ret_train, ret_test = pair_preprocess_pca(trains,tests, ratio)\n",
    "    return pair_preprocess_fv_l2norm(ret_train, ret_test, K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_pca_fv_l2norm(trains,tests, ratio=0.9, K=128):\n",
    "    ret_train, ret_test = pair_preprocess_pca(trains,tests, ratio)\n",
    "    ret_train, ret_test = pair_preprocess_fv(ret_train, ret_test, K=K)\n",
    "    return pair_preprocess_l2norm(ret_train, ret_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_pca_concat(trains,tests, ratio=0.9):\n",
    "    ret_train, ret_test = pair_preprocess_pca(trains,tests, ratio)\n",
    "    return pair_preprocess_concat(ret_train, ret_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_pca_l2norm(trains,tests, ratio=0.9):\n",
    "    ret_train, ret_test = pair_preprocess_pca(trains,tests, ratio)\n",
    "    return pair_preprocess_l2norm(ret_train, ret_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_pca_diff(trains,tests, ratio=0.9):\n",
    "    ret_train, ret_test = pair_preprocess_pca(trains,tests, ratio)\n",
    "    return pair_preprocess_diff(ret_train, ret_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pair_preprocess_concat_pca(trains,tests, ratio=0.9):\n",
    "    ret_train = []\n",
    "    ret_test = []\n",
    "    \n",
    "    for v1,v2 in trains:\n",
    "        ret_train.append(np.concatenate([v1,v2]))\n",
    "        \n",
    "    for v1,v2 in tests:\n",
    "        ret_test.append(np.concatenate([v1,v2]))\n",
    "        \n",
    "    \n",
    "    pca = PCAVectorModel(ret_train)\n",
    "    pca.n_active_components = np.argwhere(pca.eigenvalues_cumulative_ratio() > ratio)[0][0]\n",
    "    \n",
    "    ret_train,ret_test = [pca.project(vec) for vec in ret_train],[pca.project(vec) for vec in ret_test]\n",
    "        \n",
    "    return ret_train, ret_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation(folds, index, clf, postfix='', preprocess=None):\n",
    "    train_X = []\n",
    "    train_y = []\n",
    "    test_X = []\n",
    "    test_y = []\n",
    "    \n",
    "    for i,f in enumerate(folds):\n",
    "        if not i == index:\n",
    "            pairs,labels = list(zip(*f))\n",
    "            train_X += list(pairs)\n",
    "            train_y += labels\n",
    "        else:\n",
    "            pairs,labels = list(zip(*f))\n",
    "            test_X += list(pairs)\n",
    "            test_y += labels\n",
    "            \n",
    "            \n",
    "    def query_data(fname):\n",
    "        if not fname in data_cache.keys():\n",
    "            img = mio.import_pickle(fname) if fname.suffix == '.pkl' else mio.import_image(fname).pixels.ravel()\n",
    "            data_cache[fname] = img\n",
    "\n",
    "        return fname\n",
    "\n",
    "    for index, (fname1,fname2) in enumerate(train_X):\n",
    "        train_X[index] = [data_cache[query_data(fname1)], data_cache[query_data(fname2)]]\n",
    "\n",
    "    for index, (fname1,fname2) in enumerate(test_X):\n",
    "        test_X[index] = [data_cache[query_data(fname1)], data_cache[query_data(fname2)]]\n",
    "        \n",
    "    if preprocess:\n",
    "        train_X, test_X = preprocess(train_X, test_X)\n",
    "\n",
    "    train_X = np.array(train_X).astype(float)\n",
    "    test_X = np.array(test_X).astype(float)\n",
    "    \n",
    "    if len(train_X.shape) == 1:\n",
    "        train_X = train_X.reshape((train_X.shape)+(1,))\n",
    "    if len(test_X.shape) == 1:  \n",
    "        test_X = test_X.reshape((test_X.shape)+(1,))\n",
    "    \n",
    "    train_y = np.array(train_y).astype(int)\n",
    "    test_y = np.array(test_y).astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    clf.fit(train_X,train_y)\n",
    "\n",
    "    py = clf.predict(test_X)\n",
    "    \n",
    "    \n",
    "    acc = accuracy_score(test_y, py)\n",
    "    \n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(test_y, clf.decision_function(test_X), pos_label=1)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        fpr, tpr, roc_auc = [0,0,0]\n",
    "\n",
    "    \n",
    "    \n",
    "    print(acc)\n",
    "    return acc, fpr, tpr, roc_auc, clf, test_y,py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersect_validation(folds_A,folds_B, index, clf, postfix='', preprocess=None):\n",
    "    intersect_A = [folds_B[index]] + [f for i,f in enumerate(folds_A) if not i == index ]\n",
    "    intersect_B = [folds_A[index]] + [f for i,f in enumerate(folds_B) if not i == index ]\n",
    "    return validation(intersect_A, 0, clf,postfix=postfix,preprocess=preprocess),validation(intersect_B, 0, clf,postfix=postfix,preprocess=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_intersect_validation(folds_A,folds_B, clf, postfix='', preprocess=None):\n",
    "    results = []\n",
    "    for i in range(len(folds_A)):\n",
    "        results.append(intersect_validation(folds_A,folds_B, i, clf,postfix=postfix,preprocess=preprocess))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_validation(folds, clf, postfix='', preprocess=None):\n",
    "    results = []\n",
    "    for i in range(len(folds)):\n",
    "        results.append(validation(folds, i, clf,postfix=postfix,preprocess=preprocess))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fold_norm(foldA, foldB):\n",
    "    N_pairs_A = len(foldA[0])\n",
    "    N_pairs_B = len(foldB[0])\n",
    "    max_fold_pairs = np.min([N_pairs_A,N_pairs_B])\n",
    "    shuffle_A = list(range(N_pairs_A))\n",
    "    shuffle_B = list(range(N_pairs_B))\n",
    "    np.random.shuffle(shuffle_A)\n",
    "    np.random.shuffle(shuffle_B)\n",
    "    shuffle_A = shuffle_A[:max_fold_pairs]\n",
    "    shuffle_B = shuffle_B[:max_fold_pairs]\n",
    "    \n",
    "    return [list(np.array(foldA[0])[shuffle_A]),list(np.array(foldA[1])[shuffle_A])],[list(np.array(foldB[0])[shuffle_B]),list(np.array(foldB[1])[shuffle_B])]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def protocalAndPath(protocol, db_path, ext):\n",
    "    db_path = Path(db_path)\n",
    "    ret_protocol = []\n",
    "    \n",
    "    for fold in protocol:\n",
    "        ret_fold = []\n",
    "        for index, ((p1,p2), label) in enumerate(fold):\n",
    "            ret_fold.append([[Path('{}/{}{}'.format(db_path,Path(p1).stem,ext)),Path('{}/{}{}'.format(db_path,Path(p2).stem,ext))],label])\n",
    "        ret_protocol.append(ret_fold)\n",
    "\n",
    "    return ret_protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_path = Path('/homes/yz4009/wd/databases/ear/EarVerification/')\n",
    "db_type = \"bound\"\n",
    "# db_type = \"aligned\"\n",
    "\n",
    "feature = '128dsift'\n",
    "ext = '+{}.pkl'.format(feature) if not feature == '' else '.jpg'\n",
    "preprocess_part = functools.partial(pair_preprocess_pca_fv, ratio=64, K=128)\n",
    "preprocess = lambda x,y: pair_preprocess_pca(*preprocess_part(x,y), ratio=32)\n",
    "# preprocess = pair_preprocess_l2norm\n",
    "# preprocess = pair_preprocess_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = JBC()\n",
    "# clf = svm.SVC(C=1)\n",
    "# clf = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGGEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "protocol_vggear = mio.import_pickle('{}/{}/protocol.pkl'.format(db_path,'VGGEAR'), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing cov Matrixes with size: 740 * 64\n",
      "0.508108108108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/atlas/homes/yz4009/miniconda/envs/gitdev/lib/python3.5/site-packages/ipykernel/__main__.py:23: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/vol/atlas/homes/yz4009/miniconda/envs/gitdev/lib/python3.5/site-packages/ipykernel/__main__.py:24: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/vol/atlas/homes/yz4009/miniconda/envs/gitdev/lib/python3.5/site-packages/ipykernel/__main__.py:26: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/vol/atlas/homes/yz4009/miniconda/envs/gitdev/lib/python3.5/site-packages/ipykernel/__main__.py:27: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/vol/atlas/homes/yz4009/miniconda/envs/gitdev/lib/python3.5/site-packages/ipykernel/__main__.py:28: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing cov Matrixes with size: 740 * 64\n",
      "0.562162162162\n",
      "computing cov Matrixes with size: 740 * 64\n",
      "0.527027027027\n",
      "computing cov Matrixes with size: 740 * 64\n",
      "0.486486486486\n",
      "computing cov Matrixes with size: 740 * 64\n",
      "0.486486486486\n",
      "Mean acc: 0.5140540540540541\n"
     ]
    }
   ],
   "source": [
    "Bd = cross_validation(protocalAndPath(protocol_vggear, db_path/'VGGEAR'/db_type,ext), clf, postfix=feature, preprocess=preprocess)\n",
    "print('Mean acc: {}'.format(np.mean(list(zip(*Bd))[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bd[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mio.export_pickle(Bd, '/homes/yz4009/wd/PickleModel/EarRecognition/verification_bench_align_PEP.pkl', overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WPUTEDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "protocol_wputedb = mio.import_pickle('{}/{}/protocol.pkl'.format(db_path,'WPUTEDB'), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ad = cross_validation(protocalAndPath(protocol_wputedb, db_path/'WPUTEDB'/db_type,ext), clf, postfix=feature, preprocess=preprocess)\n",
    "print('Mean acc: {}'.format(np.mean(list(zip(*Ad))[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ad[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "civ_result = cross_intersect_validation(protocalAndPath(protocol_wputedb, db_path/'WPUTEDB'/db_type,ext),protocalAndPath(protocol_vggear, db_path/'VGGEAR'/db_type,ext), clf, postfix=feature, preprocess=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ac,Bc = list(zip(*civ_result))\n",
    "print('Mean acc Ac: {}'.format(np.mean(list(zip(*Ac))[0])))\n",
    "print('Mean acc Bc: {}'.format(np.mean(list(zip(*Bc))[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adv = np.mean(list(zip(*Ad))[0])\n",
    "bdv = np.mean(list(zip(*Bd))[0])\n",
    "acv = np.mean(list(zip(*Ac))[0])\n",
    "bcv = np.mean(list(zip(*Bc))[0])\n",
    "\n",
    "print([adv,acv,bdv,bcv,bcv-bdv,adv-acv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mio.export_pickle([Ad,Ac,Bd,Bc], '/homes/yz4009/wd/PickleModel/EarRecognition/verification_unaligned_DSIFT_SVM.pkl', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[Ad,Ac,Bd,Bc] = mio.import_pickle('/homes/yz4009/wd/PickleModel/EarRecognition/verification_unaligned_DSIFT_SVM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from menpo.visualize import plot_curve\n",
    "def roc_plot(methods_results, legend_names=\"\", bbox_to_anchor=(1.3, 0.5), figsize=(5,7)):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    num_folds = len(methods_results[0])\n",
    "\n",
    "    x_axis = []\n",
    "    y_axis = []\n",
    "    for method_id,results in enumerate(methods_results):\n",
    "\n",
    "        mean_tpr = 0.0\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "        for i in range(num_folds):\n",
    "            mean_tpr += np.interp(mean_fpr, results[i][1], results[i][2])\n",
    "            mean_tpr[0] = 0.0\n",
    "\n",
    "        mean_tpr /= num_folds\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "\n",
    "        plt.plot(mean_fpr, mean_tpr, '--', lw=3)\n",
    "\n",
    "        x_axis.append(mean_fpr)\n",
    "        y_axis.append(mean_tpr)\n",
    "\n",
    "        print('{:} Auc: {:5.3f}, Mean: {:6.4f}, Std: {:5.3f}'.format(legend_names[method_id], mean_auc, np.mean([r[0] for r in results]), np.std([r[0] for r in results])))\n",
    "        \n",
    "#     plot_curve(np.array(x_axis).T,np.array(y_axis).T)\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.ylabel('True positive rate (TPR)')\n",
    "    plt.xlabel('False positive Rate (FPR)')\n",
    "    plt.title('ROC curve')\n",
    "    plt.tick_params(labelsize=14)\n",
    "\n",
    "    plt.legend(legend_names, loc=10, bbox_to_anchor=bbox_to_anchor)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_plot([Ad, Ac, Bd, Bc], ['WPUTEDB+Direct+PI', 'WPUTEDB+Cross+PI', 'Our DB+Direct+PI', 'Our DB+Cross+PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Report Verification Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_compare_aligned = []\n",
    "results_compare_aligned_labels = []\n",
    "for method in ['LDA', 'SVM']:\n",
    "    for feature in ['PI','DSIFT']:\n",
    "        results_compare_aligned.append(\n",
    "            mio.import_pickle('/homes/yz4009/wd/PickleModel/EarRecognition/verification_unaligned_{}_{}.pkl'.format(feature, method))\n",
    "        )\n",
    "        results_compare_aligned_labels.append([\n",
    "            'WPUTEDB+Direct+{}+{}'.format(feature, method), \n",
    "            'WPUTEDB+Cross+{}+{}'.format(feature, method), \n",
    "            'Our DB+Direct+{}+{}'.format(feature, method), \n",
    "            'Our DB+Cross+{}+{}'.format(feature, method)\n",
    "        ])\n",
    "        \n",
    "results_compare_aligned = np.concatenate(results_compare_aligned)\n",
    "results_compare_aligned_labels = np.concatenate(results_compare_aligned_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_plot(results_compare_aligned, results_compare_aligned_labels, bbox_to_anchor=(1.2, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'SVM+int': [0.62702702702702706, 0.54864864864864871, 0.52702702702702697, 0.59999999999999998, 0.072972972972973005, 0.078378378378378355],\n",
    "    'LDA+int': [0.64648648648648654, 0.54918918918918913, 0.56594594594594594, 0.57081081081081086, 0.0048648648648649262, 0.097297297297297414],\n",
    "#     'SVM+igo':[0.62046649888935368, 0.58349243135459317, 0.6123870687392875, 0.52932042172716209, -0.083066647012125405, 0.036974067534760513],\n",
    "#     'LDA+igo':[0.62667534650736612, 0.56914678977656408, 0.6176923032157684, 0.5676226300631031, -0.050069673152665306, 0.057528556730802038],\n",
    "    'LDA+int+align':[0.67675675675675673, 0.57729729729729728, 0.56054054054054059, 0.65621621621621617, 0.095675675675675587, 0.099459459459459443],\n",
    "    'SVM+int+align':[0.65729729729729724, 0.57243243243243236, 0.55675675675675684, 0.64756756756756739, 0.090810810810810549, 0.084864864864864886],\n",
    "#     'SVM+dsift+align':[0.50148215499417503, 0.49853543197716998, 0.50658903452281734, 0.51758557246870907, 0.010996537945891727, 0.0029467230170050485],\n",
    "#     'LDA+dsift+align':[0.68480749310169531, 0.58961469083626228, 0.65152646116141866, 0.55939885707195658, -0.092127604089462078, 0.09519280226543303],\n",
    "#     'LDA+dsift': [0.7005405405405406, 0.58918918918918917, 0.62594594594594599, 0.54162162162162164, -0.084324324324324351, 0.11135135135135144],\n",
    "    'LDA+PEP+PCA+align': [0.64540540540540536, 0.58648648648648638, 0.61891891891891893, 0.63729729729729734, 0.018378378378378413, 0.058918918918918983],\n",
    "    'SVM+PEP+PCA+align': [0.62378378378378374, 0.55459459459459448, 0.60918918918918918, 0.58756756756756756, -0.021621621621621623, 0.06918918918918926],\n",
    "#     'SVM+dsiff': [0.5077264120799666, 0.50158446895955011, 0.49502824983447358, 0.49941304347826082, 0.0043847936437872437, 0.0061419431204164932],\n",
    "    'LDA+PEP+align': [0.65405405405405403, 0.58864864864864852, 0.62216216216216214, 0.63891891891891883, 0.016756756756756697, 0.065405405405405515],\n",
    "    'SVM+PEP+align':[0.63891891891891883, 0.5637837837837838, 0.60324324324324319, 0.58108108108108103, -0.022162162162162158, 0.075135135135135034],\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mio.export_pickle(results, '/homes/yz4009/wd/PickleModel/EarRecognition/verification_result.pkl', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_len = 18\n",
    "print(' method             &   Ad  &   Ac  &   Bd  &   Bc  &  Bc-Bd &  Ad-Ac \\\\\\\\')\n",
    "for k in results.keys():\n",
    "    res = results[k]\n",
    "#     print(' {} & {:4.1f}% & {:4.1f}% & {:4.1f}% & {:4.1f}% & {:5.1f}% & {:5.1f}% \\\\\\\\'.format(k + ' '*(key_len-len(k)),res[0]*100.0,res[1]*100.0,res[2]*100.0,res[3]*100.0,res[4]*100.0,res[5]*100.0))\n",
    "    print(' {} & {:6.4f} & {:6.4f} & {:6.4f} & {:6.4f} & {:7.4f} & {:7.4f} \\\\\\\\'.format(k + ' '*(key_len-len(k)),res[0],res[1],res[2],res[3],res[4],res[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Verification Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'JBC' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b3adb94bb3ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'PI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DSIFT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PEP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     results_compare_aligned.append([\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/homes/yz4009/wd/PickleModel/EarRecognition/verification_bench_{}_{}.pkl'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malignment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     ])\n\u001b[1;32m      8\u001b[0m     results_compare_aligned_labels.append([\n",
      "\u001b[0;32m/vol/atlas/homes/yz4009/gitdev/menpo/menpo/io/input/base.py\u001b[0m in \u001b[0;36mimport_pickle\u001b[0;34m(filepath, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mWhatever\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0mare\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPickle\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \"\"\"\n\u001b[0;32m--> 381\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimporter_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/atlas/homes/yz4009/gitdev/menpo/menpo/io/input/base.py\u001b[0m in \u001b[0;36m_import\u001b[0;34m(filepath, extensions_map, landmark_resolver, landmark_ext_map, landmark_attach_func, asset, importer_kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimporter_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0mimporter_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m     \u001b[0mbuilt_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimporter_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mimporter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# landmarks are iterable so check for list precisely\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/atlas/homes/yz4009/gitdev/menpo/menpo/io/input/pickle.py\u001b[0m in \u001b[0;36mpickle_importer\u001b[0;34m(filepath, asset, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \"\"\"\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle_with_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/atlas/homes/yz4009/gitdev/menpo/menpo/io/input/pickle.py\u001b[0m in \u001b[0;36m_unpickle_with_encoding\u001b[0;34m(f, encoding)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'JBC' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "alignment = 'align'\n",
    "results_compare_aligned = []\n",
    "results_compare_aligned_labels = []\n",
    "for method in ['PI','DSIFT', 'PEP', 'FV']:\n",
    "    results_compare_aligned.append([\n",
    "        mio.import_pickle('/homes/yz4009/wd/PickleModel/EarRecognition/verification_bench_{}_{}.pkl'.format(alignment,method))\n",
    "    ])\n",
    "    results_compare_aligned_labels.append([\n",
    "        '{}'.format(method),\n",
    "    ])\n",
    "        \n",
    "results_compare_aligned = np.concatenate(results_compare_aligned)\n",
    "results_compare_aligned_labels = np.concatenate(results_compare_aligned_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1e160479e65d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroc_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_compare_aligned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_compare_aligned_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_to_anchor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-ce3b4a8b1cfd>\u001b[0m in \u001b[0;36mroc_plot\u001b[0;34m(methods_results, legend_names, bbox_to_anchor, figsize)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mmean_tpr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_fpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mmean_tpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/atlas/homes/yz4009/miniconda/envs/gitdev/lib/python3.5/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36minterp\u001b[0;34m(x, xp, fp, left, right, period)\u001b[0m\n\u001b[1;32m   1672\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_interp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_interp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mperiod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe1a0377240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_plot(results_compare_aligned, results_compare_aligned_labels, bbox_to_anchor=(1.2, 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:gitdev]",
   "language": "python",
   "name": "conda-env-gitdev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
