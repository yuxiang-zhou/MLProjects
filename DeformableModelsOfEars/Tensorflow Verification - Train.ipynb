{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import menpo.io as mio\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, name, root, batch_size=1):\n",
    "        self.name = name\n",
    "        self.root = Path(root)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def get_keys(self, path='images'):\n",
    "        path = self.root / path\n",
    "        keys = [x.stem for x in path.glob('*')]\n",
    "        print('Found {} files.'.format(len(keys)))\n",
    "\n",
    "        if len(keys) == 0:\n",
    "            raise RuntimeError('No images found in {}'.format(path))\n",
    "        return tf.constant(keys, tf.string)\n",
    "\n",
    "class EarWPUTEDB(Dataset):\n",
    "    def __init__(self, batch_size=1, db_name='WPUTEDB-train'):\n",
    "        self.name = 'EarWPUTEDB'\n",
    "        self.batch_size = batch_size\n",
    "        self.root = Path('/homes/yz4009/wd/PickleModel/EarRecognition/')\n",
    "        self.dataset = mio.import_pickle(str(self.root / '{}.pkl'.format(db_name)))\n",
    "        self.num_classes = 500\n",
    "        self.shape = (250, 190)\n",
    "\n",
    "    def get_keys(self, path='images'):\n",
    "        path = self.root / path\n",
    "        keys = map(str, np.arange(len(self.dataset)))\n",
    "        print('Found {} files.'.format(len(keys)))\n",
    "\n",
    "        if len(keys) == 0:\n",
    "            raise RuntimeError('No images found in {}'.format(path))\n",
    "        return tf.constant(keys, tf.string)\n",
    "\n",
    "    def get_images(self, key, shape=None):\n",
    "        def wrapper(index):\n",
    "            pixels = self.dataset[int(index)][1].resize(self.shape).pixels.reshape(self.shape + (1,))\n",
    "            pixels = np.dstack([pixels, pixels, pixels])\n",
    "            return (pixels * 255).astype(np.float32)\n",
    "\n",
    "        image = tf.py_func(wrapper, [key],\n",
    "                                   [tf.float32])[0]\n",
    "        \n",
    "        image.set_shape(self.shape + (3,))\n",
    "        return image\n",
    "\n",
    "    def get_labels(self, key, shape=None):\n",
    "        def wrapper(index):\n",
    "            return self.dataset[int(index)][0].astype(np.int32)\n",
    "\n",
    "        label = tf.py_func(wrapper, [key],\n",
    "                                   [tf.int32])[0]\n",
    "\n",
    "        label = tf.one_hot(label, self.num_classes, dtype=tf.int32)\n",
    "        label.set_shape([500,])\n",
    "        return label, None\n",
    "\n",
    "    def get(self, *names):\n",
    "        producer = tf.train.string_input_producer(self.get_keys(),\n",
    "                                                  shuffle=True)\n",
    "        key = producer.dequeue()\n",
    "        images = self.get_images(key)\n",
    "\n",
    "        image_shape = tf.shape(images)\n",
    "        tensors = [images]\n",
    "\n",
    "        for name in names:\n",
    "            fun = getattr(self, 'get_' + name.split('/')[0])\n",
    "            use_mask = (\n",
    "                len(name.split('/')) > 1) and name.split('/')[1] == 'mask'\n",
    "\n",
    "            label, mask = fun(key, shape=image_shape)\n",
    "            tensors.append(label)\n",
    "\n",
    "        return tf.train.shuffle_batch(tensors,\n",
    "                              self.batch_size,\n",
    "                              capacity=2000, min_after_dequeue=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.slim import nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import tf_logging as logging\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_float('initial_learning_rate', 0.001,\n",
    "                          '''Initial learning rate.''')\n",
    "tf.app.flags.DEFINE_float('num_epochs_per_decay', 5.0,\n",
    "                          '''Epochs after which learning rate decays.''')\n",
    "tf.app.flags.DEFINE_float('learning_rate_decay_factor', 0.97,\n",
    "                          '''Learning rate decay factor.''')\n",
    "tf.app.flags.DEFINE_integer('batch_size', batch_size, '''The batch size to use.''')\n",
    "tf.app.flags.DEFINE_integer('num_preprocess_threads', 4,\n",
    "                            '''How many preprocess threads to use.''')\n",
    "tf.app.flags.DEFINE_string('train_dir', 'ckpt/ear_train',\n",
    "                           '''Directory where to write event logs '''\n",
    "                           '''and checkpoint.''')\n",
    "tf.app.flags.DEFINE_string('pretrained_model_checkpoint_path', \n",
    "                           '/vol/atlas/homes/gt108/Projects/ibugface/pretrained_models/resnet_v1_50.ckpt',\n",
    "                           '''If specified, restore this pretrained model '''\n",
    "                           '''before beginning any training.''')\n",
    "tf.app.flags.DEFINE_integer('max_steps', 100000,\n",
    "                            '''Number of batches to run.''')\n",
    "tf.app.flags.DEFINE_string('train_device', '/gpu:4',\n",
    "                           '''Device to train with.''')\n",
    "tf.app.flags.DEFINE_string('dataset_path', '', 'Dataset directory')\n",
    "# The decay to use for the moving average.\n",
    "MOVING_AVERAGE_DECAY = 0.9999\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def network(inputs, scale=1, output_classes=500, is_training=True):\n",
    "    with slim.arg_scope(nets.resnet_utils.resnet_arg_scope(is_training=is_training)):\n",
    "        net, _ = nets.resnet_v1.resnet_v1_50(inputs)\n",
    "    net = slim.layers.fully_connected(slim.flatten(net), output_classes, activation_fn=None, scope='logits')\n",
    "    return net\n",
    "            \n",
    "def train():\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        # Load dataset.\n",
    "        provider = EarWPUTEDB(batch_size=batch_size)\n",
    "        images, labels = provider.get('labels')\n",
    "\n",
    "        # Define model graph.\n",
    "        prediction = network(images)\n",
    "\n",
    "        # Add a smoothed l1 loss to every scale and the combined output.\n",
    "        slim.losses.softmax_cross_entropy(prediction, labels)\n",
    "\n",
    "        total_loss = slim.losses.get_total_loss()\n",
    "        tf.scalar_summary('losses/total loss', total_loss)\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(FLAGS.initial_learning_rate)\n",
    "\n",
    "    with tf.Session(graph=g) as sess:\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        if FLAGS.pretrained_model_checkpoint_path:\n",
    "            saver = tf.train.Saver([v for v in tf.trainable_variables() if 'logits' not in v.name and not 'adam' in v.name.lower()])\n",
    "            saver.restore(sess, FLAGS.pretrained_model_checkpoint_path)\n",
    "\n",
    "        train_op = slim.learning.create_train_op(\n",
    "            total_loss, optimizer, summarize_gradients=True)\n",
    "\n",
    "        logging.set_verbosity(1)\n",
    "        slim.learning.train(train_op,\n",
    "                            FLAGS.train_dir,\n",
    "                            number_of_steps=1700,\n",
    "                            save_summaries_secs=60,\n",
    "                            save_interval_secs=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2489 files.\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:gitdev]",
   "language": "python",
   "name": "conda-env-gitdev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
